<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice Chat — UPLINK Docs</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link href="https://fonts.googleapis.com/css2?family=Space+Mono:wght@400;700&family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="css/docs.css">
</head>
<body>
  <header class="topbar">
    <a href="/" class="logo">⬡ UPLINK DOCS</a>
    <nav class="topnav">
      <a href="/">Home</a>
      <a href="features.html">Features</a>
      <a href="configuration.html">Config</a>
      <a href="https://github.com/mooncompany/uplink" target="_blank">GitHub</a>
    </nav>
    <button class="hamburger" id="hamburger" aria-label="Menu">
      <span></span><span></span><span></span>
    </button>
  </header>

  <div class="docs-layout">
    <aside class="sidebar">
      <div class="sidebar-section">
        <div class="sidebar-title">Getting Started</div>
        <a href="getting-started.html">Installation</a>
        <a href="configuration.html">Configuration</a>
        <a href="cli.html">CLI Reference</a>
      </div>
      <div class="sidebar-section">
        <div class="sidebar-title">Features</div>
        <a href="features.html">Overview</a>
        <a href="voice-chat.html" class="active">Voice Chat</a>
        <a href="agents.html">Agents</a>
        <a href="artifacts.html">Artifacts</a>
        <a href="split-view.html">Split View</a>
        <a href="remote-access.html">Remote Access</a>
        <a href="themes.html">Themes</a>
      </div>
      <div class="sidebar-section">
        <div class="sidebar-title">Reference</div>
        <a href="commands.html">Commands</a>
        <a href="premium.html">Premium</a>
        <a href="faq.html">FAQ</a>
      </div>
      <div class="sidebar-section">
        <div class="sidebar-title">Support</div>
        <a href="troubleshooting.html">Troubleshooting</a>
      </div>
    </aside>

    <main class="docs-content">
      <h1>Voice Chat</h1>
      <p class="subtitle">Talk to your AI naturally — dictate messages, hear responses spoken aloud, or have a full hands-free conversation.</p>

      <div class="callout warning">
        <strong>⚠ HTTPS Required for Microphone</strong>
        Browsers only allow microphone access on secure origins. Voice input will <strong>not</strong> work over plain <code>http://</code> — you need to access Uplink via <strong>HTTPS</strong> or <strong>localhost</strong>. If you're using Uplink from another device (like your phone), set up <a href="remote-access.html">Tailscale</a> for automatic HTTPS. Text-to-speech playback works over HTTP — only the microphone requires HTTPS.
      </div>

      <h2>Voice Modes</h2>
      <p>Uplink offers three voice modes, each suited for different situations. You choose your mode in <strong>Settings → Voice &amp; TTS → Voice Mode</strong>.</p>

      <h3>Push-to-Talk (Classic)</h3>
      <p>The simplest mode. Hold the microphone button to record your message, release to send. Your speech is transcribed to text, sent to the AI, and the response is spoken back.</p>
      <ul>
        <li><strong>How it works:</strong> Hold to record → release → your speech is transcribed → AI responds → response is spoken aloud</li>
        <li><strong>Double-tap</strong> to toggle hands-free recording (auto-stops after 2 seconds of silence)</li>
        <li>Works with any STT + TTS provider combination</li>
        <li>Great for quick messages or noisy environments</li>
      </ul>

      <h3>Live Voice (Standalone)</h3>
      <p>A real-time voice conversation powered by OpenAI's Realtime API. No press-and-hold — just tap once to start talking, and the AI responds with natural voice immediately.</p>
      <ul>
        <li><strong>How it works:</strong> Tap to start → speak naturally → AI responds in real-time voice → tap to end</li>
        <li>Direct voice-to-voice conversation with OpenAI</li>
        <li>Ultra-low latency — feels like a phone call</li>
        <li>Requires an OpenAI API key</li>
        <li>The AI uses its own voice and personality</li>
      </ul>

      <h3>Agent Voice (The Big One)</h3>
      <p>A full voice bridge to your OpenClaw agent. You speak, your words are transcribed, sent to your agent (with all its tools, memory, and personality), and the response is spoken back to you. It's like having a voice conversation with your personal AI assistant.</p>
      <ul>
        <li><strong>How it works:</strong> Tap to start → speak naturally → your speech is transcribed → sent to your OpenClaw agent → agent responds with text → text is spoken aloud → you can interrupt at any time</li>
        <li>Your agent keeps its full personality, memory, and tool access</li>
        <li>Voice transcripts are saved to chat history like regular messages</li>
        <li>Supports interrupts — start talking to cut the agent off mid-sentence</li>
        <li>Requires an OpenAI API key (for transcription) and a running OpenClaw gateway</li>
      </ul>

      <h2>How the Audio Pipeline Works</h2>
      <p>Uplink uses a modern audio processing system called an <strong>AudioWorklet</strong> to capture your voice. Here's what that means for you:</p>
      <ul>
        <li><strong>No lag or stuttering</strong> — Audio processing happens on a dedicated thread, separate from the rest of the app. The interface stays smooth even during long conversations.</li>
        <li><strong>Lower latency</strong> — Your voice reaches the AI faster because there's no waiting for the main app to process it.</li>
        <li><strong>Automatic fallback</strong> — If your browser doesn't support AudioWorklet (rare, but possible on older browsers), Uplink automatically falls back to a compatible method. You don't need to do anything.</li>
      </ul>
      <p>In short: it just works, and it works well. You'll notice the difference especially in Agent Voice mode during long conversations.</p>

      <h2>Voice Activity Detection (VAD)</h2>
      <p>In <strong>Agent Voice mode</strong>, Uplink automatically detects when you start and stop speaking. You don't need to press any buttons — just talk naturally.</p>

      <h3>How it works</h3>
      <ul>
        <li>Uplink continuously monitors your microphone for speech-like sounds</li>
        <li>When it detects your voice (based on volume and frequency analysis), it starts capturing</li>
        <li>When you stop talking for about 800 milliseconds, it recognizes the pause and sends your audio for transcription</li>
        <li>Brief pauses (like thinking mid-sentence) won't trigger a premature send — VAD waits to be sure you're done</li>
      </ul>

      <h3>What makes it reliable</h3>
      <ul>
        <li><strong>Frequency-aware</strong> — It doesn't just listen for loud sounds. It specifically looks for human speech frequencies (85–3500 Hz), so background music or a fan won't trigger it.</li>
        <li><strong>Confirmation thresholds</strong> — Speech must be detected for 150ms before it's confirmed as talking (prevents false starts from a cough or bump). Silence must last 800ms before it's confirmed as a pause (prevents cutting you off mid-thought).</li>
        <li><strong>Works in real-time</strong> — Checks 20 times per second with zero impact on performance.</li>
      </ul>

      <h2>Interrupts</h2>
      <p>In <strong>Agent Voice mode</strong>, you can interrupt the AI while it's speaking. Just start talking — Uplink will:</p>
      <ol>
        <li><strong>Stop the audio</strong> — The AI's voice stops immediately</li>
        <li><strong>Save what was said</strong> — The partial response is kept in chat history (marked with a dash to show it was cut short)</li>
        <li><strong>Cancel the rest</strong> — The server stops generating the remaining response</li>
        <li><strong>Listen to you</strong> — Your microphone unmutes and Uplink starts listening for your next message</li>
      </ol>
      <p>This makes conversations feel natural. You don't have to wait for the AI to finish a long answer before asking a follow-up or changing direction.</p>

      <h2>Text-to-Speech (TTS) Providers</h2>
      <p>Uplink supports five TTS engines. You choose which one to use in <strong>Settings → Voice &amp; TTS</strong>. Each has different tradeoffs between quality, speed, cost, and privacy.</p>

      <h3>ElevenLabs (Cloud)</h3>
      <p>The highest quality voice synthesis available. Natural, expressive, and highly realistic.</p>
      <ul>
        <li><strong>Quality:</strong> ★★★★★ — Best available</li>
        <li><strong>Cost:</strong> Paid (free tier available with character limits) — <a href="https://elevenlabs.io" target="_blank">elevenlabs.io</a></li>
        <li><strong>Setup:</strong> Enter your ElevenLabs API key in Settings → Voice &amp; TTS</li>
        <li><strong>Voices:</strong> Large library including custom and cloned voices</li>
        <li><strong>Requires:</strong> Internet connection</li>
      </ul>

      <h3>OpenAI TTS (Cloud)</h3>
      <p>OpenAI's text-to-speech API. High quality with natural prosody and intonation.</p>
      <ul>
        <li><strong>Quality:</strong> ★★★★☆ — Very natural</li>
        <li><strong>Cost:</strong> Paid (per character) — uses your OpenAI API key</li>
        <li><strong>Setup:</strong> Your OpenAI API key is shared with the chat API — no extra configuration</li>
        <li><strong>Voices:</strong> alloy, ash, ballad, coral, echo, fable, nova, onyx, sage, shimmer</li>
        <li><strong>Models:</strong> <code>tts-1</code> (faster) or <code>tts-1-hd</code> (higher quality)</li>
        <li><strong>Requires:</strong> Internet connection</li>
      </ul>

      <h3>Edge TTS (Free Cloud)</h3>
      <p>Microsoft's Edge TTS API. Excellent quality with hundreds of voices across dozens of languages — and it's completely free.</p>
      <ul>
        <li><strong>Quality:</strong> ★★★★☆ — Surprisingly good for free</li>
        <li><strong>Cost:</strong> Free — no API key required</li>
        <li><strong>Setup:</strong> Select "Edge TTS" as your engine and pick a voice. That's it.</li>
        <li><strong>Voices:</strong> Hundreds of voices in 45+ languages</li>
        <li><strong>Requires:</strong> Internet connection</li>
        <li><strong>Note:</strong> In Agent Voice mode, Edge TTS is the default fallback if no OpenAI key is available</li>
      </ul>

      <h3>Piper (Local)</h3>
      <p>A fast, lightweight TTS engine that runs entirely on your machine — no internet needed, no GPU needed.</p>
      <ul>
        <li><strong>Quality:</strong> ★★★☆☆ — Good, with many community voice models</li>
        <li><strong>Cost:</strong> Free — runs locally</li>
        <li><strong>Setup:</strong>
          <ol>
            <li>Download a Piper voice model (<code>.onnx</code> file) from the <a href="https://github.com/rhasspy/piper" target="_blank">Piper voices repository</a></li>
            <li>Set the <code>PIPER_MODEL</code> environment variable to point to your model file</li>
            <li>Optionally set <code>PIPER_EXECUTABLE</code> and <code>PIPER_CONFIG</code> if needed</li>
          </ol>
        </li>
        <li><strong>Voices:</strong> Many community models in various languages</li>
        <li><strong>Requires:</strong> Nothing — runs on CPU</li>
      </ul>

      <div class="code-block">
        <div class="code-block-header">
          <span>bash</span>
          <button class="copy-btn">Copy</button>
        </div>
        <pre><code>PIPER_MODEL=/path/to/voice-model.onnx</code></pre>
      </div>

      <h3>Coqui XTTS (Local GPU)</h3>
      <p>A high-quality local TTS engine. Produces the most natural-sounding local voices, but requires an NVIDIA GPU.</p>
      <ul>
        <li><strong>Quality:</strong> ★★★★☆ — Best local quality</li>
        <li><strong>Cost:</strong> Free — runs locally</li>
        <li><strong>Setup:</strong>
          <ol>
            <li>Install and start the XTTS server (separate from Uplink)</li>
            <li>Enter the server URL in Settings → Voice &amp; TTS → TTS Server URL (default: <code>http://localhost:8020</code>)</li>
          </ol>
        </li>
        <li><strong>Requires:</strong> NVIDIA GPU with at least 4 GB VRAM. Runs on CPU but too slow for real-time conversation.</li>
      </ul>

      <div class="code-block">
        <div class="code-block-header">
          <span>bash</span>
          <button class="copy-btn">Copy</button>
        </div>
        <pre><code>pip install TTS
python -m TTS.server --model_name tts_models/multilingual/multi-dataset/xtts_v2</code></pre>
      </div>

      <h3>Quick Comparison</h3>
      <div class="table-wrap">
        <table>
          <thead>
            <tr><th>Engine</th><th>Quality</th><th>Cost</th><th>Runs Where</th><th>Internet?</th><th>Setup</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>ElevenLabs</strong></td><td>★★★★★</td><td>Paid</td><td>Cloud</td><td>Yes</td><td>API key</td></tr>
            <tr><td><strong>OpenAI TTS</strong></td><td>★★★★☆</td><td>Paid</td><td>Cloud</td><td>Yes</td><td>API key (shared)</td></tr>
            <tr><td><strong>Edge TTS</strong></td><td>★★★★☆</td><td>Free</td><td>Cloud</td><td>Yes</td><td>None</td></tr>
            <tr><td><strong>Piper</strong></td><td>★★★☆☆</td><td>Free</td><td>Your machine</td><td>No</td><td>Model download</td></tr>
            <tr><td><strong>XTTS</strong></td><td>★★★★☆</td><td>Free</td><td>Your machine</td><td>No</td><td>GPU + server</td></tr>
          </tbody>
        </table>
      </div>

      <h2>Speech-to-Text (STT) Providers</h2>
      <p>STT converts your spoken words into text. You choose your provider in <strong>Settings → Voice &amp; TTS</strong>.</p>

      <h3>OpenAI Whisper (Cloud)</h3>
      <p>OpenAI's cloud-based speech-to-text. Highly accurate across many languages.</p>
      <ul>
        <li><strong>Cost:</strong> Paid (~$0.006/minute) — uses your OpenAI API key</li>
        <li><strong>Setup:</strong> Your OpenAI API key is shared with the chat API</li>
        <li><strong>Model:</strong> <code>whisper-1</code></li>
        <li><strong>Languages:</strong> 50+ languages with excellent accuracy</li>
      </ul>

      <h3>Groq Whisper (Cloud)</h3>
      <p>Extremely fast transcription powered by Groq's specialized hardware. Has a generous free tier.</p>
      <ul>
        <li><strong>Cost:</strong> Free tier available (with rate limits)</li>
        <li><strong>Setup:</strong> Get a free API key at <a href="https://console.groq.com" target="_blank">console.groq.com</a> and enter it in Settings</li>
        <li><strong>Model:</strong> <code>whisper-large-v3-turbo</code> (faster) or <code>whisper-large-v3</code> (more accurate)</li>
        <li><strong>Speed:</strong> Noticeably faster than other cloud options</li>
      </ul>

      <h3>faster-whisper (Local)</h3>
      <p>Run Whisper entirely on your own machine. Excellent accuracy, works offline, completely private.</p>
      <ul>
        <li><strong>Cost:</strong> Free — runs locally</li>
        <li><strong>Setup:</strong>
          <ol>
            <li>Install and start the server</li>
            <li>Enter <code>http://localhost:8000</code> in Settings → Voice &amp; TTS → STT Server URL</li>
          </ol>
        </li>
        <li><strong>Privacy:</strong> Audio never leaves your machine</li>
      </ul>

      <div class="code-block">
        <div class="code-block-header">
          <span>bash</span>
          <button class="copy-btn">Copy</button>
        </div>
        <pre><code># Install and run
pip install faster-whisper-server
faster-whisper-server --host 0.0.0.0 --port 8000

# Or via Docker
docker run -d -p 8000:8000 fedirz/faster-whisper-server

# For GPU acceleration
docker run -d --gpus all -p 8000:8000 fedirz/faster-whisper-server</code></pre>
      </div>

      <h3>Browser STT (Built-in)</h3>
      <p>Your browser's built-in speech recognition using the Web Speech API. Zero setup required.</p>
      <ul>
        <li><strong>Cost:</strong> Free</li>
        <li><strong>Setup:</strong> None — works out of the box</li>
        <li><strong>Accuracy:</strong> Varies by browser (Chrome is best, others may be limited)</li>
        <li><strong>Note:</strong> Most browsers send audio to their own cloud service for processing, so this isn't truly local despite being "built-in"</li>
      </ul>

      <h2>Setting Up Each Voice Mode</h2>

      <h3>Push-to-Talk Setup</h3>
      <ol>
        <li>Go to <strong>Settings → Voice &amp; TTS</strong></li>
        <li>Set <strong>Voice Mode</strong> to "Push-to-talk"</li>
        <li>Choose a <strong>TTS engine</strong> and configure it (API key, voice, etc.)</li>
        <li>Choose an <strong>STT engine</strong> and configure it</li>
        <li>Click the microphone button in the chat input to start recording</li>
      </ol>

      <h3>Live Voice Setup</h3>
      <ol>
        <li>Go to <strong>Settings → Voice &amp; TTS</strong></li>
        <li>Set <strong>Voice Mode</strong> to "Live Voice"</li>
        <li>Make sure you have an <strong>OpenAI API key</strong> configured (Settings → Connection)</li>
        <li>Tap the microphone button to start a live voice session</li>
        <li>Tap again to end it</li>
      </ol>

      <h3>Agent Voice Setup</h3>
      <ol>
        <li>Go to <strong>Settings → Voice &amp; TTS</strong></li>
        <li>Set <strong>Voice Mode</strong> to "Agent Voice"</li>
        <li>Make sure you have:
          <ul>
            <li>An <strong>OpenAI API key</strong> configured (for transcription)</li>
            <li>A running <strong>OpenClaw gateway</strong> (for your agent)</li>
          </ul>
        </li>
        <li>Optionally choose a TTS engine for the agent's voice (OpenAI TTS or Edge TTS)</li>
        <li>Tap the microphone button to start — your agent's name appears in the status bar</li>
        <li>Speak naturally. When you pause, your words are sent to the agent.</li>
        <li>The agent responds with voice. You can interrupt at any time by speaking.</li>
        <li>Tap the button again to end the session.</li>
      </ol>

      <h2>Pipelined TTS (Agent Voice)</h2>
      <p>In Agent Voice mode, Uplink doesn't wait for the entire response before starting to speak. As soon as the first sentence of the agent's response is ready, it starts speaking — while the rest of the response is still being generated.</p>
      <p>This means you hear the first words almost immediately, even for long responses. The experience feels conversational rather than "wait, then listen."</p>

      <h2 id="troubleshooting">Troubleshooting</h2>

      <h3>Microphone not working</h3>
      <ul>
        <li><strong>Check HTTPS:</strong> You must be on <code>https://</code> or <code>localhost</code>. Plain <code>http://</code> blocks mic access.</li>
        <li><strong>Check permissions:</strong> Your browser may have blocked mic access. Look for a camera/mic icon in the address bar.</li>
        <li><strong>Try a different browser:</strong> Chrome and Edge have the best mic support.</li>
        <li><strong>Remote access?</strong> Use <a href="remote-access.html">Tailscale</a> for automatic HTTPS on other devices.</li>
      </ul>

      <h3>No sound / TTS not playing</h3>
      <ul>
        <li><strong>Check your volume</strong> — sounds obvious, but it happens.</li>
        <li><strong>Check the TTS engine</strong> is configured correctly in Settings → Voice &amp; TTS.</li>
        <li><strong>Check the API key</strong> for cloud providers (ElevenLabs, OpenAI).</li>
        <li><strong>Try Edge TTS</strong> — it's free and requires no API key. Good for testing.</li>
      </ul>

      <h3>Voice is choppy or laggy</h3>
      <ul>
        <li><strong>Network issues:</strong> Cloud TTS/STT depends on your internet connection. Try a local provider.</li>
        <li><strong>Audio context blocked:</strong> Some browsers block audio playback until you interact with the page. Click somewhere first.</li>
        <li><strong>Agent Voice lag:</strong> If the agent takes a while to respond, that's gateway processing time, not an audio issue. The pipelined TTS plays the first sentence as soon as it's available.</li>
      </ul>

      <h3>STT isn't transcribing correctly</h3>
      <ul>
        <li><strong>Background noise:</strong> Try a quieter environment or a closer microphone.</li>
        <li><strong>Wrong language:</strong> Some STT providers default to English. Check your provider's language settings.</li>
        <li><strong>Browser STT limitations:</strong> Built-in browser STT is less accurate than Whisper-based options. Try Groq (free) or OpenAI Whisper.</li>
      </ul>

      <h3>Agent Voice: "Real-time voice module not loaded"</h3>
      <ul>
        <li>Make sure you're running the latest version of Uplink.</li>
        <li>Check the browser console for errors (F12 → Console).</li>
        <li>Ensure your OpenAI API key is valid and has access to the Realtime API.</li>
      </ul>

      <h3>Agent Voice: Agent not responding</h3>
      <ul>
        <li>Verify your OpenClaw gateway is running (<code>openclaw gateway status</code>).</li>
        <li>Check that the Gateway URL in Settings points to <code>http://127.0.0.1:23248</code> (or your gateway's local address).</li>
        <li>Look at the Uplink server logs for error messages.</li>
      </ul>

      <h3>Echo or feedback in Agent Voice</h3>
      <ul>
        <li>This is handled automatically — Uplink mutes your microphone while the agent is speaking and unmutes it when the agent finishes. If you're still hearing echo, make sure you're not using external speakers near your microphone.</li>
      </ul>

      <h2>Tips</h2>
      <ul>
        <li><strong>Use headphones</strong> in Agent Voice mode to prevent the AI's voice from being picked up by your microphone.</li>
        <li><strong>Edge TTS is a great starting point</strong> — it's free, requires no setup, and sounds surprisingly natural.</li>
        <li><strong>Groq Whisper is the best free STT</strong> — fast, accurate, and has a generous free tier.</li>
        <li><strong>You can mix and match</strong> — Use any STT provider with any TTS provider. They're independent.</li>
        <li><strong>Voice transcripts appear in chat</strong> — Everything said in Agent Voice mode is saved to your conversation history, so you have a written record of voice conversations.</li>
      </ul>

      <div class="docs-footer">
        <p>UPLINK Docs — Built by <a href="https://moonco.pro" target="_blank">Moon Company</a>. Open source under MIT.</p>
      </div>
    </main>
  </div>

  <script src="js/docs.js"></script>
</body>
</html>
